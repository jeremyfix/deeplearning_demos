TestImageToLabel:
  model:
    cls: "ImageToLabel"
    params: 
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "label_on_image"
    params: 
      labels_from_url: https://raw.githubusercontent.com/onnx/models/main/vision/classification/synset.txt
  output_type: "image"

# Image classification
Classification-MobileNetv2.7:
  model: 
    cls: "ONNX"
    params: 
      url: https://github.com/onnx/models/raw/main/vision/classification/mobilenet/model/mobilenetv2-7.onnx
      input_field_name: "data"
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "label_on_image"
    params: 
      labels_from_url: https://raw.githubusercontent.com/onnx/models/main/vision/classification/synset.txt
  output_type: "image"

Classification-Resnet50-v2.7:
  model: 
    cls: "ONNX"
    params:
      url: https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v2-7.onnx
      input_field_name: "data"
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "label_on_image"
    params: 
      labels_from_url: https://raw.githubusercontent.com/onnx/models/main/vision/classification/synset.txt
  output_type: "image"


# Object detection
# The model really expects  (1, 480, 640, 3)
# TODO : how to adapt the preprocess step ?
ObjectDetection-RetinaNet-ResNet101:
  model:
    cls: "ONNX"
    params: 
      url: https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/retinanet/model/retinanet-9.onnx
      input_field_name: "input"
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "bbox_overlay"
    params:
  output_type: "image"

Segmentation-VOC-FCN-Resnet50-12-int8:
  model: 
    cls: "ONNX"
    params:
      url: https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/fcn/model/fcn-resnet50-12-int8.onnx
      input_field_name: "input"
  preprocessing: 
    - square_pad:
    - resize:
        width: 520
        height: 520
    - save_asset: 
        key: "resized_img"
    - scale:
        value: 255.0
    - normalize: 
        mus: [0.485, 0.456, 0.406]
        stds: [0.229, 0.224, 0.225]
    - transpose:
        dims: [2, 0, 1]
    - astype: 
        ttype: "float32"
    - add_frontdim:
  input_type: "image"
  postprocessing: 
    cls: "segmentation_overlay"
    params: 
      num_classes: 21
      colorized: True
      blended: True
  output_type: "image"

ObjectDetection-Yolov8n:
  model: 
    cls: "ONNX"
    params:
      url: https://github.com/jeremyfix/onnx_models/raw/main/Vision/ObjectDetection/Yolov8/yolov8n.pt
      input_field_name: "images"
  preprocessing: 
    - square_pad:
    - resize:
        width: 640
        height: 640
    - save_asset: 
        key: "resized_img"
    - scale:
        value: 255.0
    - transpose:
        dims: [2, 0, 1]
    - astype: 
        ttype: "float32"
    - add_frontdim:
  input_type: "image"
  postprocessing: 
    cls: "yolov8_bbox"
    params: 
      labels_from_url: "https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/datasets/coco.yaml"
  output_type: "image"

# TODO: fix segmentation mask computation/drawing
Segmentation-Yolov8n:
  model: 
    cls: "ONNX"
    params:
      url: https://github.com/jeremyfix/onnx_models/raw/main/Vision/Segmentation/Yolov8/yolov8n-seg.onnx
      input_field_name: "images"
  preprocessing: 
    - square_pad:
    - resize:
        width: 640
        height: 640
    - save_asset: 
        key: "resized_img"
    - scale:
        value: 255.0
    - transpose:
        dims: [2, 0, 1]
    - astype: 
        ttype: "float32"
    - add_frontdim:
  input_type: "image"
  postprocessing: 
    cls: "segmentation_overlay"
    params: 
      num_classes: 21
      colorized: True
      blended: True
  output_type: "image"
