TestImageToLabel:
  model:
    cls: "ImageToLabel"
    params: 
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "label_on_image"
    params: 
      labels_from_url: https://raw.githubusercontent.com/onnx/models/main/vision/classification/synset.txt
  output_type: "image"

# Image classification
Classification-MobileNetv2.7:
  model: 
    cls: "ONNX"
    params: 
      url: https://github.com/onnx/models/raw/main/vision/classification/mobilenet/model/mobilenetv2-7.onnx
      input_field_name: "data"
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "label_on_image"
    params: 
      labels_from_url: https://raw.githubusercontent.com/onnx/models/main/vision/classification/synset.txt
  output_type: "image"

Classification-Resnet50-v2.7:
  model: 
    cls: "ONNX"
    params:
      url: https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v2-7.onnx
      input_field_name: "data"
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "label_on_image"
    params: 
      labels_from_url: https://raw.githubusercontent.com/onnx/models/main/vision/classification/synset.txt
  output_type: "image"


# Object detection
# The model really expects  (1, 480, 640, 3)
# TODO : how to adapt the preprocess step ?
ObjectDetection-RetinaNet-ResNet101:
  model:
    cls: "ONNX"
    params: 
      url: https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/retinanet/model/retinanet-9.onnx
      input_field_name: "input"
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "bbox_overlay"
    params:
  output_type: "image"

#TODO: the model advises to use image of size 520 x 520 minimum
Segmentation-VOC-FCN-Resnet50-12-int8:
  model: 
    cls: "ONNX"
    params:
      url: https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/fcn/model/fcn-resnet50-12-int8.onnx
      input_field_name: "input"
  preprocessing: "imagenet_preprocess"
  input_type: "image"
  postprocessing: 
    cls: "segmentation_overlay"
    params: 
      num_classes: 21
      colorized: True
      blended: True
  output_type: "image"
